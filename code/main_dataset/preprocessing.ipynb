{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../../data/main_dataset/main_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude irrelevant columns from dataset\n",
    "def exclude_columns(df):\n",
    "  columns_to_exclude = ['collection_time', 'sender_first_name', 'sender_last_name', 'sender_display_name', 'sender_username', 'fwd_from_user_name', 'post_author', 'is_group_elem', 'message_group_id']\n",
    "  return df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# filter out messages that are replies to messages that are not in the dataset\n",
    "def filter_out_of_dataset_replies(df, df_full):\n",
    "  # remove messages that are replies to messages that are not in the datasetet\n",
    "  replies = df[df['reply_to_message_id'].notna()]\n",
    "\n",
    "  for index, row in replies.iterrows():\n",
    "    reply_to_message_id = row['reply_to_message_id']\n",
    "    chat_handle = row['chat_handle']\n",
    "    same_chat_df = df_full[df_full['chat_handle'] == chat_handle]\n",
    "\n",
    "    # if message is a reply to a message that is not in the dataset, remove it.\n",
    "    if reply_to_message_id not in same_chat_df['telegram_message_id'].values:\n",
    "      df = df.drop(index)\n",
    "\n",
    "  return df\n",
    "\n",
    "# detect languages of rows\n",
    "def detect_row_langs(text):\n",
    "  if pd.isna(text):\n",
    "    return None\n",
    "  \n",
    "  text = str(text)\n",
    "\n",
    "  try:\n",
    "    return detect_langs(text)\n",
    "  except LangDetectException:\n",
    "    return None\n",
    "  \n",
    "# get unique languages of row\n",
    "def get_langset(row):\n",
    "  langs = set()\n",
    "  if row['webpage_description_lang']:\n",
    "    langs.update([lang.lang for lang in row['webpage_description_lang']])\n",
    "  if row['message_text_lang']:\n",
    "    langs.update([lang.lang for lang in row['message_text_lang']])\n",
    "  return list(langs)\n",
    "\n",
    "# get unique languages with confidence greater than 0.5 of row\n",
    "def get_confident_langset(row):\n",
    "  langs = set()\n",
    "  if row['webpage_description_lang']:\n",
    "    langs.update([lang.lang for lang in row['webpage_description_lang'] if lang.prob > 0.5])\n",
    "  if row['message_text_lang']:\n",
    "    langs.update([lang.lang for lang in row['message_text_lang'] if lang.prob > 0.5])\n",
    "  return list(langs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "df_raw = pd.read_csv(raw_data_path, index_col=0)\n",
    "\n",
    "# preprocessing which applies to all data, so no filtering\n",
    "print(\"Preprocessing\")\n",
    "print(f\"Row count before: {len(df_raw)}\")\n",
    "\n",
    "print(\"Excluding columns...\")\n",
    "df_raw = exclude_columns(df_raw)\n",
    "\n",
    "# add language info\n",
    "print(\"Detecting webpage description languages...\")\n",
    "df_raw['webpage_description_lang'] = df_raw['webpage_description'].apply(detect_row_langs)\n",
    "print(\"Detecting message text languages...\")\n",
    "df_raw['message_text_lang'] = df_raw['message_text'].apply(detect_row_langs)\n",
    "print(\"Detecting unique language set for each row...\")\n",
    "df_raw['langset'] = df_raw.apply(get_langset, axis=1)\n",
    "print(\"Detecting unique language set with confidence > 0.5 for each row...\")\n",
    "df_raw['langset_confident'] = df_raw.apply(get_confident_langset, axis=1)\n",
    "\n",
    "# filter out messages where none of the text is german or english\n",
    "print(\"Filtering out messages where none of the text is german or english...\")\n",
    "df_raw = df_raw[df_raw['langset'].apply(lambda langs: 'de' in langs or 'en' in langs)]\n",
    "print(f\"Row count after: {len(df_raw)}\")\n",
    "\n",
    "print(\"Filter out messages where message text language is not german or english...\")\n",
    "df_raw = df_raw[df_raw['message_text_lang'].apply(lambda langs: langs == None or any(lang.lang in ['de', 'en'] for lang in langs))]\n",
    "print(f\"Row count after: {len(df_raw)}\")\n",
    "\n",
    "print(\"Filter out messages where webpage description language is not german or english...\")\n",
    "df_raw = df_raw[df_raw['webpage_description_lang'].apply(lambda langs: langs == None or any(lang.lang in ['de', 'en'] for lang in langs))]\n",
    "print(f\"Row count after: {len(df_raw)}\")\n",
    "\n",
    "print(\"Filter out messages where some of the text is confidently not german or english...\")\n",
    "df_raw = df_raw[df_raw['langset_confident'].apply(lambda langs: all(lang in ['de', 'en'] for lang in langs))]\n",
    "print(f\"Row count after: {len(df_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating dfs for preprocessing and full dataset...\")\n",
    "df_prepro = df_raw.copy()\n",
    "df_additional = df_raw.copy()\n",
    "\n",
    "print(f\"Row count before: {len(df_prepro)}\")\n",
    "\n",
    "# remove polls\n",
    "print(\"Removing polls...\")\n",
    "df_prepro = df_prepro[df_prepro['message_media_type'] != 'MessageMediaPoll']\n",
    "print(f\"Row count after removing polls: {len(df_prepro)}\")\n",
    "\n",
    "# remove messages without text and webpage description\n",
    "print(\"Removing messages without text and webpage description...\")\n",
    "df_prepro = df_prepro[df_prepro['message_text'].notna() | df_prepro['webpage_description'].notna()]\n",
    "print(f\"Row count after removing messages without text and webpage description: {len(df_prepro)}\")\n",
    "\n",
    "# remove messages where message text consists of only a url and no webpage description is attached\n",
    "print(\"Removing messages with only a url...\")\n",
    "df_prepro = df_prepro[~(df_prepro['message_text'].str.contains('http') & ~df_prepro['message_text'].str.contains(' ') & df_prepro[\"webpage_description\"].isna())]\n",
    "print(f\"Row count after removing messages with only a url: {len(df_prepro)}\")\n",
    "\n",
    "# remove messages shorter than 15 chars which are not replies to other messages and have no webpage attached\n",
    "print(\"Removing short messages...\")\n",
    "df_prepro = df_prepro[\n",
    "  ~(\n",
    "    (df_prepro['message_text'].str.len() < 15) & \n",
    "    (df_prepro['reply_to_message_id'].isna()) & \n",
    "    (df_prepro['message_media_type'] != 'MessageMediaWebPage')\n",
    "  )\n",
    "]\n",
    "print(f\"Row count after removing short messages: {len(df_prepro)}\")\n",
    "\n",
    "# remove messages that are replies to messages that are not in the dataset\n",
    "print(\"Removing replies to messages not in dataset...\")\n",
    "df_prepro = filter_out_of_dataset_replies(df_prepro, df_additional)\n",
    "print(f\"Row count after removing replies to messages not in dataset: {len(df_prepro)}\")\n",
    "\n",
    "# shuffle dataset\n",
    "print(\"Shuffling...\")\n",
    "df_prepro = df_prepro.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Done!\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove language related columns again\n",
    "#df_prepro = df_prepro.drop(columns=['webpage_description_lang', 'message_text_lang', 'langset', 'langset_confident'])\n",
    "#df_additional = df_additional.drop(columns=['webpage_description_lang', 'message_text_lang', 'langset', 'langset_confident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepro.to_csv('../../data/main_dataset/main_dataset-prepro.csv')\n",
    "df_additional.to_csv('../../data/main_dataset/main_dataset-additional.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_something_foreign = df_raw.copy()\n",
    "\n",
    "def get_confident_langset(row):\n",
    "  langs = []\n",
    "  if row['webpage_description_lang']:\n",
    "    langs.extend([lang.lang for lang in row['webpage_description_lang'] if lang.prob > 0.5])\n",
    "  \n",
    "  if row['message_text_lang']:\n",
    "    langs.extend([lang.lang for lang in row['message_text_lang'] if lang.prob > 0.5])\n",
    "  return list(set(langs))\n",
    "\n",
    "df_something_foreign[\"confident_langset\"] = df_something_foreign.apply(get_confident_langset, axis=1)\n",
    "df_something_foreign = df_something_foreign[df_something_foreign['confident_langset'].apply(lambda langs: any(lang not in ['de', 'en'] for lang in langs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_something_foreign))\n",
    "\n",
    "for index, row in df_something_foreign.head(100).iterrows():\n",
    "  print(\"---\")\n",
    "  print(row[\"message_text_lang\"])\n",
    "  print(row[\"webpage_description_lang\"])\n",
    "  print(row[\"langset\"])\n",
    "  print(row[\"confident_langset\"])\n",
    "  print(row[\"message_text\"])\n",
    "  print(row[\"webpage_description\"])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
