{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "data_path = '../../data/24_09_28-test_scrape/24_09_28-test_scrape-prepro.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic queries\n",
    "Below, a number of complex keyword queries for a set of topics are defined. These queries are used to filter the dataset for relevant documents. The topics are:\n",
    "- Gender and sexual identity\n",
    "- COVID-19 and vaccines\n",
    "- Migration\n",
    "- Brandenburg\n",
    "- Greta Thunberg\n",
    "- Alice Weidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print a string to the terminal, wrapping it to fit the terminal width\n",
    "\"\"\"\n",
    "def print_wrapped_to_fit_terminal(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    width = shutil.get_terminal_size(fallback=(80, 20)).columns\n",
    "    print(textwrap.fill(text, width=width))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Filter a dataframe by a keyword query on a specified column. The keyword query can have the following rules:\n",
    "- \"all\": all keywords must be present in the column\n",
    "- \"any\": at least one of the keywords must be present in the column\n",
    "- \"none\": none of the keywords can be present in the column\n",
    "\"\"\"\n",
    "def filter_by_keywords(df, column, keywords={}, ignore_case=True):\n",
    "    query = pd.Series([True] * len(df)) \n",
    "\n",
    "    if \"all\" in keywords:\n",
    "        for keyword in keywords[\"all\"]:\n",
    "            query &= df[column].str.contains(keyword, na=False, case=ignore_case)\n",
    "\n",
    "    if \"any\" in keywords:\n",
    "        some_query = pd.Series([False] * len(df))\n",
    "        for keyword in keywords[\"any\"]:\n",
    "            some_query |= df[column].str.contains(keyword, na=False, case=ignore_case)\n",
    "        query &= some_query\n",
    "\n",
    "    if \"none\" in keywords:\n",
    "        for keyword in keywords[\"none\"]:\n",
    "            query &= ~df[column].str.contains(keyword, na=False, case=ignore_case)\n",
    "\n",
    "    return df[query]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Filter a dataframe of messages by keywords in the message text, webpage title, and webpage description\n",
    "\"\"\"\n",
    "def filter_message_data_by_keywords(df, keywords={}, ignore_case=True):\n",
    "    column_filtered = [\n",
    "        filter_by_keywords(df, \"message_text\", keywords, ignore_case),\n",
    "        filter_by_keywords(df, \"webpage_title\", keywords, ignore_case),\n",
    "        filter_by_keywords(df, \"webpage_description\", keywords, ignore_case),\n",
    "    ]\n",
    "\n",
    "    return pd.concat(column_filtered).drop_duplicates()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Display the matches for a keyword/regular expression in the message text, webpage title, and webpage description columns of a dataframe\n",
    "\"\"\"\n",
    "def get_matches_for_keyword_in_message_data(df, keyword, ignore_case=True):\n",
    "    def find_matches(row):\n",
    "        message_text = row.get(\"message_text\", \"\")\n",
    "        webpage_description = row.get(\"webpage_description\", \"\")\n",
    "        webpage_title = row.get(\"webpage_title\", \"\")\n",
    "\n",
    "        all_matches = []\n",
    "        \n",
    "        message_matches = list(re.finditer(keyword, message_text, re.IGNORECASE)) if ignore_case else list(re.finditer(keyword, message_text))\n",
    "        for match in message_matches:\n",
    "            start = max(0, match.start() - 20)\n",
    "            end = min(len(message_text), match.end() + 20)\n",
    "            all_matches.append(message_text[start:end])\n",
    "\n",
    "        webp_matches = list(re.finditer(keyword, webpage_description, re.IGNORECASE)) if ignore_case else list(re.finditer(keyword, webpage_description))\n",
    "        for match in webp_matches:\n",
    "            start = max(0, match.start() - 20)\n",
    "            end = min(len(webpage_description), match.end() + 20)\n",
    "            all_matches.append(webpage_description[start:end])\n",
    "\n",
    "        webp_title_matches = list(re.finditer(keyword, webpage_title, re.IGNORECASE)) if ignore_case else list(re.finditer(keyword, webpage_title))\n",
    "        for match in webp_title_matches:\n",
    "            start = max(0, match.start() - 20)\n",
    "            end = min(len(webpage_title), match.end() + 20)\n",
    "            all_matches.append(webpage_title[start:end])\n",
    "\n",
    "        return all_matches\n",
    "\n",
    "    df[\"all_matches\"] = df.apply(find_matches, axis=1)\n",
    "    \n",
    "    return df[\"all_matches\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "greta_keywords = {\n",
    "  \"any\": ['[Tt]hunberg', '[Gg]reta']\n",
    "}\n",
    "df_greta = filter_message_data_by_keywords(df, keywords=greta_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_keywords = {\n",
    "  \"any\": [\n",
    "      'trans(?!(port|form|paren|pir|action|it|kript|atlanti|fer|fusion|aktion|human|cript|lat|nation|nistri))',\n",
    "      '(?<!(undle|vorra|leidi))(?<!(fol|rre|dri|ewe|sor|tra|tei))gender',\n",
    "      'bin채r',\n",
    "      'binary',\n",
    "      'geschlecht',\n",
    "      'queer',\n",
    "      'lgbt'\n",
    "      ]\n",
    "}\n",
    "df_trans = filter_message_data_by_keywords(df, keywords=trans_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant_keywords = {\n",
    "  \"all\": [\n",
    "     '(migrant|asyl|fl체cht|refug|ausl채nd|t체rk|arab|muslim|islam|terror)'\n",
    "  ]\n",
    "}\n",
    "df_migrant = filter_message_data_by_keywords(df, keywords=migrant_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brandenburg_election_keywords = {\n",
    "   \"any\": ['brandenburg']\n",
    "}\n",
    "\n",
    "df_brandenburg_election = filter_message_data_by_keywords(df, keywords=brandenburg_election_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weidel_keywords = {\n",
    "  \"any\": ['weidel']\n",
    "}\n",
    "\n",
    "weidel_df = filter_message_data_by_keywords(df, keywords=weidel_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine_keywords = {\n",
    "  \"any\": [\"corona\", \"covid\",\"(?<!(sch|ngl))impf\",\"vacc\",\"pandem\", \"mrna\", \"spritze\"]\n",
    "}\n",
    "\n",
    "vaccine_df = filter_message_data_by_keywords(df, keywords=vaccine_keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
